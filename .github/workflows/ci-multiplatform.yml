name: Multi-Platform Tests

on:
  workflow_dispatch:
  # push:
  #   branches: [main, perf/*]
  #   paths:
  #     - 'python/bustapi/app.py'
  #     - 'src/server/**'
  #     - '.github/workflows/ci-multiplatform.yml'

jobs:
  test-multiprocessing:
    name: Test on ${{ matrix.os }} (Py ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    env:
      PYO3_USE_ABI3_FORWARD_COMPATIBILITY: 1
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.12"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Set up Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Create venv
        run: uv venv .venv

      - name: Install dependencies (Unix)
        if: runner.os != 'Windows'
        run: |
          VENV_PY=./.venv/bin/python
          uv pip install maturin pytest httpx requests sqlmodel --python $VENV_PY
          $VENV_PY -m maturin develop --release
          echo "VENV_PY=$VENV_PY" >> $GITHUB_ENV

      - name: Install dependencies (Windows)
        if: runner.os == 'Windows'
        shell: bash
        run: |
          VENV_PY=./.venv/Scripts/python.exe
          uv pip install maturin pytest httpx requests sqlmodel --python $VENV_PY
          $VENV_PY -m maturin develop --release
          echo "VENV_PY=$VENV_PY" >> $GITHUB_ENV

      - name: Test Multiprocessing Workers
        shell: bash
        run: |
          # Create a simple test server
          cat > /tmp/test_server.py << 'EOF'
          from bustapi import BustAPI
          import sys
          import os

          app = BustAPI()

          @app.turbo_route("/")
          def index():
              return {"pid": os.getpid(), "status": "ok"}

          if __name__ == "__main__":
              # Test with 2 workers
              workers = 2
              print(f"Starting server with {workers} workers on {sys.platform}...")
              app.run(host="127.0.0.1", port=8000, workers=workers, debug=False)
          EOF

          # Start server in background
          $VENV_PY /tmp/test_server.py &
          SERVER_PID=$!
          sleep 5

          # Make test requests
          echo "Making test requests..."
          for i in {1..10}; do
            curl -s http://127.0.0.1:8000/ || echo "Request $i failed"
          done

          # Cleanup
          kill $SERVER_PID 2>/dev/null || true
          echo "Test completed!"

      - name: Run pytest
        shell: bash
        run: |
          $VENV_PY -m pytest tests -v --ignore=tests/test_benchmark*.py || true

      - name: Install wrk (Unix only)
        if: runner.os != 'Windows'
        run: |
          if [[ "$RUNNER_OS" == "Linux" ]]; then
            sudo apt-get update && sudo apt-get install -y wrk
          elif [[ "$RUNNER_OS" == "macOS" ]]; then
            brew install wrk || true
          fi

      - name: Performance Benchmark
        shell: bash
        run: |
          echo "=== BustAPI Performance Benchmark ==="
          echo "Platform: $RUNNER_OS"
          echo "Python: ${{ matrix.python-version }}"
          echo ""
          
          # Create benchmark server
          cat > /tmp/bench_server.py << 'EOF'
          from bustapi import BustAPI
          app = BustAPI()
          
          @app.turbo_route("/")
          def index():
              return "Hello, World!"
          
          @app.turbo_route("/json")
          def json_endpoint():
              return {"hello": "world", "framework": "BustAPI"}
          
          if __name__ == "__main__":
              app.run(host="127.0.0.1", port=8888, workers=4, debug=False)
          EOF
          
          # Start server
          $VENV_PY /tmp/bench_server.py &
          SERVER_PID=$!
          sleep 5
          
          # Run benchmark
          if command -v wrk &> /dev/null; then
            echo "--- Benchmark with wrk (10s) ---"
            echo "Root endpoint (/):"
            wrk -t4 -c50 -d10s http://127.0.0.1:8888/
            echo ""
            echo "JSON endpoint (/json):"
            wrk -t4 -c50 -d10s http://127.0.0.1:8888/json
          else
            echo "--- Python Concurrent Benchmark (wrk not available) ---"
            echo "Running 1000 parallel requests via Python..."
            cat > /tmp/bench_client.py << 'PYEOF'
          import time
          import urllib.request
          from concurrent.futures import ThreadPoolExecutor, as_completed
          
          URL = 'http://127.0.0.1:8888/'
          REQUESTS = 1000
          WORKERS = 10
          
          def make_request(i):
              try:
                  urllib.request.urlopen(URL, timeout=5)
                  return True
              except:
                  return False
          
          start = time.time()
          success = 0
          with ThreadPoolExecutor(max_workers=WORKERS) as executor:
              futures = [executor.submit(make_request, i) for i in range(REQUESTS)]
              for f in as_completed(futures):
                  if f.result():
                      success += 1
          elapsed = time.time() - start
          print(f'Completed {success}/{REQUESTS} requests in {elapsed:.2f}s')
          print(f'RPS: {success/elapsed:.0f} req/s')
          print(f'Workers: {WORKERS} threads')
          PYEOF
            $VENV_PY /tmp/bench_client.py
          fi
          
          # Cleanup
          kill $SERVER_PID 2>/dev/null || true
          echo ""
          echo "=== Benchmark Complete ==="
